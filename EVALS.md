# ğŸ§ª Jarvis Evaluation Report

**Generated:** 2026-01-25 15:16:57

## ğŸ“Š Model Comparison

This report compares eval results across officially supported models.
Use this to understand the performance tradeoffs when choosing a model.

| Metric | llama3.2:3b | gpt-oss:20b |
|--------|--------|--------|
| âœ… Passed | 43 | 46 |
| âŒ Failed | 3 | 0 |
| â­ï¸ Skipped | 0 | 0 |
| ğŸ“Š Total | 49 | 49 |
| â±ï¸ Duration | 64.7s | 343.4s |
| ğŸ“ˆ Pass Rate | ğŸŸ¢ 93.5% | ğŸŸ¢ 100.0% |

### Pass Rate Visualization

**llama3.2:3b:** ğŸŸ¢ `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘` **93.5%**
**gpt-oss:20b:** ğŸŸ¢ `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ` **100.0%**

### ğŸ’¡ Model Selection Guide

| Model | Best For | Trade-offs |
|-------|----------|------------|
| `llama3.2:3b` | Quick responses, lower RAM usage | May struggle with complex reasoning |
| `gpt-oss:20b` | Best accuracy, complex tasks | Slower, requires more RAM |

---

## ğŸ“‹ Detailed Test Results

| Test Case | llama3.2:3b | gpt-oss:20b |
|-----------|----------|----------|
| Agent calls webSearch for info queries | âœ… | âœ… |
| Agent chains search â†’ fetch for details | âœ… | âœ… |
| Agent recalls interests before personalized search (mocked) | âœ… | âœ… |
| Agent uses memory + nutrition data | âœ… | âœ… |
| Bad: deflection without attempting answer | âŒ | âœ… |
| Bad: empty acknowledgment | âœ… | âœ… |
| Bad: generic greeting ignores query | âœ… | âœ… |
| Enrichment results appear in system message | âœ… | âœ… |
| Extraction with explicit quantities | âœ… | âœ… |
| Good: brief but informative | âœ… | âœ… |
| Good: complete weekly forecast | âœ… | âœ… |
| Handles ambiguous portion descriptions | âœ… | âœ… |
| LLM uses enrichment, skips redundant recallConversation | âœ… | âœ… |
| Live weather query with real LLM | âŒ | âœ… |
| Live: LLM checks memory before asking about interests | âœ… | âœ… |
| Location context flows to search queries | âœ… | âœ… |
| LogMealTool stores meals with macros | âœ… | âœ… |
| Returns NONE for non-food inputs | âœ… | âœ… |
| Returns valid JSON with all required fields | âœ… | âœ… |
| Simple meal baseline (2 boiled eggs) | âœ… | âœ… |
| caesar-salad | âœ… | âœ… |
| cheeseburger-fries | âœ… | âœ… |
| chicken-broccoli | âŒ | âœ… |
| eggs-toast | âœ… | âœ… |
| oatmeal-banana | âœ… | âœ… |
| personalized news | âœ… | âœ… |
| personalized restaurant | âœ… | âœ… |
| pizza-slice | âœ… | âœ… |
| protein-shake | âœ… | âœ… |
| spaghetti-bolognese | âœ… | âœ… |
| specific topic recall | âœ… | âœ… |
| test_hot_window_mode_indicated_in_prompt | âœ… | âœ… |
| test_returns_none_when_ollama_unavailable | âœ… | âœ… |
| test_system_prompt_has_echo_guidance | âœ… | âœ… |
| test_tts_text_included_for_echo_detection | âœ… | âœ… |
| time-based recall | âœ… | âœ… |

### ğŸ“– Legend

| Symbol | Meaning |
|--------|---------|
| âœ… | Passed |
| âŒ | Failed |
| â­ï¸ | Skipped (missing dependencies) |
| ğŸ”¸ | Expected failure (known limitation) |
| ğŸ‰ | Unexpectedly passed (bug fixed!) |
| â– | Not run for this model |

---

*Report generated by Jarvis eval suite*
